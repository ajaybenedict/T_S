import { Component, EventEmitter, Input, Output, SimpleChanges } from '@angular/core';
import { PageEvent } from '@angular/material/paginator';
import { Observable, Subscriber, finalize, of } from 'rxjs';
import { environment } from '../environments/environment.int';
import { DataState } from '../core/services/data-state';
import { JsonHelper } from '../core/services/AIAssistant/json-helper';
@Component({
  selector: 'ai-overview',
  templateUrl: './ai-overview.component.html'
})
export class AiOverviewComponent {
  
  @Input() messages: any = [];  
  @Input() model: string = "gpt-4o";
  @Output() finalOutput = new EventEmitter<string>();

  openAiResult$ = of('');
  finalText: string = "";
  finalCompleteText: string = "";
  temperature = 0.1;
  max_tokens = 3000;  //this is max output tokens that can be generated by AI
  n = 1;
  @Input() roleWithLongMessage = 'assistant'
  @Input() trackChanges: boolean = false;
  private prefix = (window.location.href.includes('localhost')) ? "" : "/core-ppc";
  private apiBaseUrl = `${this.dataState.getBaseUrl()}${this.prefix}/api/v1/assistant`;

  
  constructor(private dataState: DataState) {

    this.apiBaseUrl = JsonHelper.getCoreUrl(this.apiBaseUrl);
  }
  ngOnInit() {
    this.setModel();
    this.processMessages();
  }
  setModel() {
    if (!this.model || this.model == "")
      this.model = "gpt-4o"
  }

  ngOnChanges(changes: SimpleChanges) {
    if (this.trackChanges) {
      this.setModel();
    }
  }

  processMessages() :void {
    if (this.messages && this.messages.length > 0) {

        this.openAiResult$ = this.doOpenAICall(
          this.messages,
          this.temperature,
          this.model,
          this.max_tokens,
          this.n
        ).pipe(
          finalize(() => {
            this.finalOutput.emit(this.finalCompleteText);
          })
        );
      
    }

  }

  public doOpenAICall(
    messages: any,
    temperature: any,
    model: string,
    max_tokens: any,
    n: any
  ): Observable<string> {
    const url = `${this.apiBaseUrl}/chat-completions`;
    return new Observable<string>((observer: Subscriber<string>) => {
      const xhr = new XMLHttpRequest();
      xhr.open('POST', url);
      xhr.setRequestHeader('Content-Type', 'application/json');
      xhr.withCredentials = true; // Ensures cookies are sent with the request

      xhr.onprogress = () => {
        const newUpdates = xhr.responseText
          .replace('data: [DONE]', '')
          .trim()
          .split('data: ')
          .filter(Boolean);

        const newUpdatesParsed: string[] = newUpdates.map(update => {
          try {
            const parsed = JSON.parse(update);
            if (parsed && parsed.choices) {
              return parsed.choices[0].delta?.content || '';
            } else {
              return "";
            }
          } catch (e) {
            return "";
          }
        });

        this.finalCompleteText = newUpdatesParsed.join(''); // Store all content
        // this.finalText = this.finalCompleteText.split("```json")[0]; // Stop at ```json if it exists
        observer.next(this.finalCompleteText);
      };

      xhr.onreadystatechange = () => {
        if (xhr.readyState === 4) {
          if (xhr.status === 200) {
            observer.complete();
          } else if (xhr.status === 400 && model === "gpt-3.5-turbo") {
            observer.error(new Error('Request failed with status ' + xhr.status));
          } else {
            observer.error(new Error('Request failed with status ' + xhr.status));
          }
        }
      };

      xhr.send(JSON.stringify({
        model,
        messages,
        max_tokens,
        n,
        temperature,
        frequency_penalty: 0,
        presence_penalty: 0,
        stream: true
      }));

      return () => xhr.abort();
    });
  }
}
